Week2:

LIBNAME mydata  "/courses/d1406ae5ba27fe300" access = readonly;

DATA new; set mydata.addhealth_pds;// DATA setp
LABEL H1DA1="Times of working around the hourse during the past week"
	     H1DA2="Times of doing hobbies during the past week";  //表头
       
IF feature1 = 1;
IF feature2 LE 0;

//Logic部分：
= EQ
~= ^= NE
> GT
< LE
>= GE
<= LE
PROC SORT; by AID;  //将主键作为排序

PROC FREQ; TABLES feature1 feature2; //显示frequency
RUN; //execute above all

Week3:
Data management
1.data missing
  IF F1 = 9 then F1 = .;
	
2. Blank information
IF F1 = . Then F1 = 11;   /*空着和unknow不一样，空着和不回答是两回事。

3. Create secondary variable
ACTIVITY = H1DA1 + H1DA2;
IF ACTIVITY < 3 then ACTIVITY = 0;
ELSE IF ACTIVITY >= 3 then ACTIVITY =1;  
PROC PRINT; VAR H1DA1 H1DA2 ACTIVITY;  看看对不对

4. Category
IF H1DA1 = 0 THEN Group = 0;
ELSE IF H1DA1 = 1 THEN Group = 1;
ELSE IF H1DA1 = 2 THEN Group = 2;
ELSE IF H1DA1 = 3 THEN Group = 3;
ELSE Group = .;

Week4:
category:
PRO GCHART; VBAR F1/Discrete type = PCT width = 30; /*VBAR = 垂直 ; Discrete = category  PCT = percentage*/
PRO FREQ

quantitative:
PRO GCHART; VBAR F2/ type = PCT; 
PROC UNIVARIATE; VAR H1DA8;/*查看 mean median mode

2 variable relationship:
bar chart for 2 category
PROC GCHART; VBAR categorical_x_variable/discrete Type = mean Sumvar = categorical_y_variable;

scattorplot for 2 quantitative

PROC GPLOT; Plot y_variable * x_variable

Course2

Week 1
As long as adequately large samples and an adequantly large number of samples are used from a population, the 
distribution of the statistics of the samples will be normally distributed

Hypothesis Testing
1.Specify the null(H0) and the alternate(Ha) hypothesis(定义两个猜测)
2.Choose a sample
3. Access the evidence
4.Draw conclusions

P Value <= 5%  (Significance level of a test) Reject null hypothesis   -- h0 是错的
P value > 5% data do not provide enough evidence to accept the Ha   -----H1是错的
p value = the number of times out of 100 we would be wrong in rejecting the H0

3种 statictical tools：
ANOVA analysis of variance
x2 - chi Square test of independence
r - correlation coefficient

C -> Q (ANOVA)
C -> C (x2)
Q -> Q (pearson correlation r)
Q -> C (x2)


1.ANOVA F test:
    are the differences among the sample means due to true difference among the population means or
    merely due to sampling variability
    F = variation among sample means / variation within groups
    
    So, F is big, 两个因素是相关的，Ha接受

	PROC ANOVA; Class explanatory variable;
	MODEL response variable =  explanatory variable;
	MEANS explanatory variable;
if explanatory variable more than 2 group, ANOVA do not tell us which groups are different from the others!!

1-2 Using post hoc test to see difference when x feature is more than 2 categories
one of post hoc is DUNCAN test

	MEANS explanatory variable/DUNCAN;

Incorrectly rejects the H0 ---Type 1 error


Courses2 
Week 2

Chi Squre
c -> c

1. get expected value
use column total * row total / total
X**2 = SUM((observed count - expected count)**2 / expected count)

So 2 by 2 case, X**2 > 3.84 is large, difference is large
如果不是2 by 2 ，还是得看P value
如何使用chiSQuare？
	PROC FREQ; TABLES yfeature * xfeature/CHISQ;

如果是 Explanatory variable > 2 levels, 不能确定哪些是有关系的
也使用post hoc test来判断，不过比之前ANOVA里要复杂！
这里叫做Bonferroni Adjustment
改变p value的值，不适用0.05 而是p/c (c是需要对比的次数)
比如有5个类别， 则对比次数为 4 + 3 + 2 + 1 = 10 次
1.所以 adjusted p value = 0.05 / 10
2.选取 explantory variable中的两种，（假设这里response variable只有2种）， 用PROC FREQ; TABLES yfeature * xfeature/CHISQ;
得出pvalue，如果 < adjusted p value, 有关，否则无关

使用这种选择对于所有的两两之间：
DATA COMPARISON1; SET New;
IF H1DA1 = 0 or H1DA1 = 1;
PROC SORT; BY AID;
PROC FREQ; Tables H1GH1A * H1DA1/ CHISQ;
RUN;
Q - > C
变成C -> C

Course 2
Week 3:
Q -> Q Pearson correlation (measure a linear relationship between 2 Quantitative variables)
How to describe scotter plot:
form:1 Linear    2.curvilinear 

Pearson correlation coefficient = r (-1= < r <= 1)(strength of a linear relationship between 2 Q variables)
r的平方表示 百分之多少的 one variable can be predicted by the other.
0 表示 weak relationship -1 或者1 都是 strong relationship。 只是一个是递增关系，一个递减。
这个值只对linear关系有效，对curvilinear关系无效

这里P value <= 0.05表示有关系

所以：
1.使用 PROC GPLOT; Ploy y variable * x variable;  //看图
      PROC CORR; Var 1 variable 2variable 3variable; //看r和p
      会显示 r < p  很奇怪的表示，但是无所谓了。


Courser2
Week 4

第三种variable   ：  Moderator缓和
在每一种moderator的情况下，x和y变量都有关系吗？
了解第三个变量Moderator的影响；假设这里是C->Q的情况，
1.使用ANOVA方法分析。
则代码变为：
	PROC SORT; By moderator;
	PROC ANOVA; Class x;
	MODEL y = x;
	MEANS x; By Moderator;
	
2.在C-》C的情况下，使用 CHI SQUARE
PRO SORT; By Moderator;
PROC FREQ; Tanles y* x/CHISQ; BY Moderator;
如果moderator各个情况下x和y的关系一样，则说明moderator does not moderate the relationship between x and y 

3.Q->Q pearson情况下
 PROC SORT; by moderator;
 PROC CORR; VAR x y; BY moderator;
 


Week3

Week3 - 1
data: 1.observation data
      2. experimental data
      
      confounding variable  =  lurking variable (干扰因素)
      需要控制这些变量
      confunding variable is associated with x and y.可以找！！！
      
 Week3 - 2
 Linear Regression and Logistic regression
 Q -> Q
 PROC GLM; model
 quantitative response = explantory variable
 
得出的表格里有intercept and slope
可以得出公式 y = intercept + intercept下面的那个值(slope) * x

C -> Q   C是binary的情况
PROC GLM; model quantitative response = explantory variable / solution

Linear Regression Assumptions:
1.Normality  is normal distribution
2.Linearity     associations is linear(a straight line) 
3.Homoscedasticity  variability is response bvariable is same at all levels of explantory variable
4.independence  数据个体之间不相关，比如同一个教室的学生的成绩相关，因为老师一样。 但是这个是数据决定了，没办法。
5.outliers    extreme value
6.multicollinearity explanatory variables are highly correlated with each other  (choose just one)

为了更好理解，我们需要center the response variable mean to 0. 
这样we can look at the association between another explantory variable and response variable.


Week 3-3
Multiple regression
1.两个 response variable 1.binary category 2. Quantitative variable  首先centering these variables 
1.变成0 和 1
2.减去mean（相当于mean变成0）

PROC GLM; model H1GH60 = H1DA1 H1DA8_2 / solution;
两个变量顺序无所谓。 出现的表格里Estimate 这一栏是正的，则positively associated with response variable
So， 当单独使用 PROC GLM; model y = x / solution时，p value < 0.05, 之后 添加一个新的x2
PROC GLM; model y = x1 x2/ solution 
x 的 p value > 0.05, 则x2 就是confounding 
x2 confounds the relationship between x and y!!!
也就是说只有x的时候看起来x和y有关系
但是当有多个x的时候，之前以为有关系的x可以看出其实是无关系的！

PROC GLM; model y = x1 x2/ solution clparm;  Use clparm to see 95% confidence interval

总结： intercept 就是bias  estimate 就是x前面的系数， 95%confidence 就是we are 95% certain that the true
population parameter in this interval
还有一个特点，无关的变量，他的range包括了0， 也就是说很可能系数为0， 也就是无关！

/*Q->Q的图和方程的直线， clm表示画出95% confidence interval*/
PROC SGPLOT; reg x = H1DA8_2 y = H1GH60 / lineattrs= (color = red thickness = 3) clm;
yaxis label = "H1GH60";
xaxis label = "H1DA8_2";
run;

有时候直线表示的并不好，用曲线才能表示关系，所以加入quadratic regression line
PROC SGPLOT; reg x = H1DA8_2 y = H1GH60 / lineattrs= (color = red thickness = 3)degree = 1 clm;
PROC SGPLOT; reg x = H1DA8_2 y = H1GH60 / lineattrs= (color = red thickness = 3)degree = 2 clm;
degree = 1 means line
degree = 2 means quadratic line
如果发现
PROC GLM; model y = x/ solution clparm; 得出的R -squared值低，可以试一试使用x squared 或者三次方
因为可能直线不能很好表示


Missepecification 缺少重要的explantory variable
Evaluation model:   主要是把结果放到一个stdres变量里

* request regression diagnostic plots;

PROC GLM plots(unpack) = all;                          /*plots 表示要打印出诊断图 diagnostic plot*/
model y = x1 x2 x3 / solution clparm;
output residual = res student = stdres out = results;  / 选项residual = res要求使用非标准残差的列，而选项student = res要求使用标准化残差的列。
			                               /Finally, the out = results option asks for another data set that includes the 							       /regression analysis results.

会打印出所有图，其中有几个比较重要的
1.q-q plot
	We can find that in q-q plot, points do not follow a straight line absolutely. So it does not follow a perfectly normal distribution. We need to add some other explanatory to our model.
	
2.standardized residuals for all observations
	如果1%的在2.5std外或者 5%在2std外，则模型不好,需要更多explantory variable。 两个都满足才好
3.leverage plot
	find outliers. 如果比较左边，说明没啥影响力.
	
Normalizing or standardizing the values:

* plot of standardized residuals for each observation;
proc gplot;
label stdres="Standardized Residual" aid="AID";
plot stdres*AID/vref=0; 
run;



Partial regression plot:

data new3;
set new;
x2 = x * x;
run;
PROC reg plots = partial;
model y = x x2 / partial;
run;

使用partial regression plot我们可以发现在控制其他的x情况下，某一个explantory variable 和y的关系是否是线性还是曲线或者很weak



outlier and leverage plot
数据中影响大的和outlier
outlier是在2std以外的


Week3 - 4
If explantory variable x1 is category and more than 2 group
假如有4种情况 ABCD
要compare A to BCD。 A is reference group, BCD are comparison groups

PROC GLM;
class x1 (ref = "A");             //不写class则会以为是quantitative explantory variable
model y = x1 x2 x3 / solution;

如果不写ref的值，则默认是ref = last group


If response is binary categorical variable, we do not use multiple regression
we use Logistic regression

PROC LOGISTIC descending; model binary response = explantory;


Odd ratios: probability of event occuring in one group compared to the p of event occuring in another group
range : 0 -> infinity
odd ratios = 1: our model is statistically nonsigmificant (x and y no relationship)
odd ratios > 1: as x increases, y more likely
odd ratios < 1: as x increases, y is less likely
example:
odd ratios = 3.4: my sample with x occur are 3.4 times more likely to have y than who without x occurs after control other xs
记住对于y来说，0是没出现，1是出现

Course 4

week1

Linear regression 
accuracy = mean squared error
Variance = change in parameter estimates across different data sets
Bias = how far off model estimated values are from true value

increase variance will decrease bias, we need find model with low variance and low bias
Overfitting: model has low training mean squared error and large test mean squared error

Decision Tree:
	making binary splits in a sample to maxinize correct classfication
	all cut-points are tested
	separation yielding the minimum impurity or error is selected
Building decision tree:


ods graphics on;   //用来显示结果到比如HTML
proc hpsplit seed = 15531; //hpsplit: tree based;   seed : 用来cross validation 
class categorical y categorical x;
model categorical y = all explanatory variables;
grow entropy;
prune costcomplexity;
grow criteria:
1.GINI index
2.Entropy
3. residual sums of squares
 Be Careful: (model event level choose low value of response variable)所以如果原本1是yes 0是no，则他会显示0.如果想显示1则需要吧no变成2.
prune criteria:(do pruning to avoid over fitting)
1.Cost-complexity  (both Q and C response variable) (make trade-off between error rate and size of tree)
会出现一个图： vertical line show tree with lowest cross valiadated ASE
horizontal reference line : average standard error + 1 standard error
Select smallest tree that as an ASE below horizontal reference line.

会出现一个Model Based confusion matrix
display error rate

会出现一个图 ROC curve
1.Sensitivity: True positive rate
2.Specificity: True negative rate
会出现一个表： variable important
当explanatory variables中有几个high related时， 可能只会显示一个的重要性的值，但是不代表其他就不重要


优缺点：
不同的seed意味着不同的随机，可能结果model不同

proc hpsplit assignmissing = popular seed = 15531; // missing data observation will be assigned to the most popular.默认是drop

strength:
selects from a large number of variables and interactions that are most important

can predict Categorical and quantitative response variable

weakness:
small changes in data can lead to different splits 
not reproducible on future data
